name: Playwright E2E Tests

on:
  pull_request:
    branches: [ main, master, develop ]
  push:
    branches: [ main, master, develop ]
  workflow_dispatch:

jobs:
  test:
    timeout-minutes: 60
    runs-on: ubuntu-latest
    outputs:
      test_failed: ${{ steps.playwright-tests.outputs.test_failed }}
      failed_count: ${{ steps.playwright-tests.outputs.failed_count }}
      flaky_count: ${{ steps.playwright-tests.outputs.flaky_count }}
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'yarn'

    - name: Install dependencies
      run: yarn install

    - name: Install Playwright Browsers
      run: yarn playwright:install

    - name: Create test environment file
      run: |
        echo "SEED_DEFAULT_USER_PASSWORD=s3cret" > .env.local
        echo "PAGINATION_PAGE_SIZE=10" >> .env.local

    - name: Create mock AWS exports for CI
      run: |
        yarn copy:mock:awsexports
        yarn copy:mock:awsexportses5

    # - name: Start local server
    #   run: |
    #     yarn run dev &
    #     # Wait for the server to start
    #     for i in {1..30}; do
    #       if curl -s http://localhost:3000 > /dev/null; then
    #         echo "Server is up and running"
    #         break
    #       fi
      
    - name: Run Playwright tests
      id: playwright-tests
      run: |
        set +e  # Don't exit immediately on command failure so we can capture output
        
        # Run tests and capture both output and exit code
        yarn playwright:test --project=chromium e2e-journey.spec.ts > test_output.log 2>&1
        TEST_EXIT_CODE=$?
        
        # Display the test output
        cat test_output.log
        
        # Check for any failures in the output
        if grep -q "failed\|flaky" test_output.log || [ "$TEST_EXIT_CODE" -ne 0 ]; then
          echo "Tests failed or were flaky!"
          echo "test_failed=true" >> $GITHUB_OUTPUT
          echo "TEST_FAILED=true" >> $GITHUB_ENV
          
          # Count failures and flaky tests
          FAILED_COUNT=$(grep -o "[0-9]\+ failed" test_output.log | head -1 | grep -o "[0-9]\+" || echo "0")
          FLAKY_COUNT=$(grep -o "[0-9]\+ flaky" test_output.log | head -1 | grep -o "[0-9]\+" || echo "0")
          
          echo "failed_count=$FAILED_COUNT" >> $GITHUB_OUTPUT
          echo "flaky_count=$FLAKY_COUNT" >> $GITHUB_OUTPUT
          
          echo "Found $FAILED_COUNT failed tests and $FLAKY_COUNT flaky tests"
        else
          echo "All tests passed!"
          echo "test_failed=false" >> $GITHUB_OUTPUT
          echo "TEST_FAILED=false" >> $GITHUB_ENV
          echo "failed_count=0" >> $GITHUB_OUTPUT
          echo "flaky_count=0" >> $GITHUB_OUTPUT
        fi
      env:
        CI: true
        # Enable screenshots and videos on failure for PR runs
        PLAYWRIGHT_HTML_REPORT: playwright-report
        PLAYWRIGHT_TEST_BASE_URL: http://localhost:3000

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: playwright-report-chromium
        path: |
          playwright-report/
          test-results/
        retention-days: 30

    - name: Upload HTML report
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: playwright-html-report-chromium
        path: playwright-report/
        retention-days: 30
    
    - name: Check test results
      if: always()
      run: |
        # Check if the playwright tests failed based on the environment variable set in the test step
        if [ "$TEST_FAILED" = "true" ]; then
          echo "âŒ Playwright tests failed!"
          echo "FINAL_TEST_STATUS=failure" >> $GITHUB_ENV
        else
          echo "âœ… All Playwright tests passed!"
          echo "FINAL_TEST_STATUS=success" >> $GITHUB_ENV
        fi

    - name: Capture DOM snapshots on failure
      if: always() && env.TEST_FAILED == 'true' && github.event_name == 'pull_request'
      run: |
        # Create a directory for DOM snapshots
        mkdir -p dom-snapshots
        
        # Find all test result directories that contain error contexts
        find test-results -name "*.md" -path "*/error-context.md" | while read error_file; do
          # Extract test name from path
          test_dir=$(dirname "$error_file")
          test_name=$(basename "$test_dir")
          
          # Copy error context and any related files
          cp "$error_file" "dom-snapshots/${test_name}-error-context.md" || true
          
          # Look for trace files in the same directory
          find "$test_dir" -name "trace.zip" -exec cp {} "dom-snapshots/${test_name}-trace.zip" \; || true
          
          # Look for screenshot files
          find "$test_dir" -name "*.png" -exec cp {} "dom-snapshots/${test_name}-screenshot.png" \; || true
          
          # Look for video files
          find "$test_dir" -name "*.webm" -exec cp {} "dom-snapshots/${test_name}-video.webm" \; || true
        done
        
        # Create a summary of captured artifacts
        echo "# DOM Snapshots and Debug Artifacts" > dom-snapshots/README.md
        echo "" >> dom-snapshots/README.md
        echo "This directory contains debugging artifacts from failed tests:" >> dom-snapshots/README.md
        echo "" >> dom-snapshots/README.md
        ls -la dom-snapshots/ | grep -v "^total" | tail -n +2 | while read line; do
          file=$(echo "$line" | awk '{print $9}')
          if [ "$file" != "README.md" ]; then
            echo "- \`$file\`" >> dom-snapshots/README.md
          fi
        done
        
        echo "Captured $(find dom-snapshots -type f ! -name README.md | wc -l) debug artifacts"

    - name: Upload DOM snapshots and debug artifacts
      uses: actions/upload-artifact@v4
      if: always() && env.TEST_FAILED == 'true' && github.event_name == 'pull_request'
      with:
        name: dom-snapshots-and-debug-artifacts
        path: |
          dom-snapshots/
          test-results/
        retention-days: 7

    - name: Final test result check
      if: always()
      run: |
        # Exit with failure code if tests failed, but only after all artifacts are uploaded
        if [ "$TEST_FAILED" = "true" ]; then
          echo "âŒ Exiting with failure code due to test failures"
          exit 1
        else
          echo "âœ… All tests passed - exiting successfully"
          exit 0
        fi

        
  # Job to aggregate and comment on PR
  report:
    needs: [test]
    runs-on: ubuntu-latest
    if: always() && github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download all test artifacts
      uses: actions/download-artifact@v4
      with:
        path: artifacts

    - name: Check test job status
      id: test-status
      run: |
        # Check if the test job failed and get failure counts
        if [ "${{ needs.test.result }}" = "failure" ] || [ "${{ needs.test.outputs.test_failed }}" = "true" ]; then
          echo "test_failed=true" >> $GITHUB_OUTPUT
          echo "âŒ Tests failed"
          
          # Get failure counts from test step outputs if available
          FAILED_COUNT="${{ needs.test.outputs.failed_count || '0' }}"
          FLAKY_COUNT="${{ needs.test.outputs.flaky_count || '0' }}"
          
          echo "failed_count=$FAILED_COUNT" >> $GITHUB_OUTPUT
          echo "flaky_count=$FLAKY_COUNT" >> $GITHUB_OUTPUT
        else
          echo "test_failed=false" >> $GITHUB_OUTPUT
          echo "failed_count=0" >> $GITHUB_OUTPUT
          echo "flaky_count=0" >> $GITHUB_OUTPUT
          echo "âœ… Tests passed"
        fi

    - name: Create test summary
      run: |
        echo "# ğŸ­ Playwright E2E Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Add status badge based on test results
        if [ "${{ steps.test-status.outputs.test_failed }}" = "true" ]; then
          echo "## âŒ Test Status: FAILED" >> $GITHUB_STEP_SUMMARY
        else
          echo "## âœ… Test Status: PASSED" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Test Coverage" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Authentication flows" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Transaction management" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Bank account operations" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… Notifications handling" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… User settings management" >> $GITHUB_STEP_SUMMARY
        echo "- âœ… End-to-end user journeys" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Browsers Tested" >> $GITHUB_STEP_SUMMARY
        echo "- ğŸŒ Chromium (Desktop)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Show final status based on job result
        if [ "${{ steps.test-status.outputs.test_failed }}" = "true" ]; then
          echo "âŒ Tests failed. Please check the artifacts for details." >> $GITHUB_STEP_SUMMARY
        else
          echo "âœ… All tests passed!" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Comment PR
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request'
      with:
        script: |
          // Get test status from job result
          const testJobResult = '${{ needs.test.result }}';
          const testFailed = '${{ needs.test.outputs.test_failed }}';
          const failedCount = '${{ needs.test.outputs.failed_count || "0" }}';
          const flakyCount = '${{ needs.test.outputs.flaky_count || "0" }}';
          
          let testStatus = 'âœ… All E2E tests passed!';
          let statusIcon = 'âœ…';
          let statusDetails = '';
          
          if (testJobResult === 'failure' || testFailed === 'true') {
            testStatus = 'âŒ Some E2E tests failed. Please check the details in the workflow.';
            statusIcon = 'âŒ';
            
            if (failedCount !== '0' || flakyCount !== '0') {
              statusDetails = `\n\n**Test Results:**\n- Failed: ${failedCount}\n- Flaky: ${flakyCount}`;
            }
          }
          
          const comment = `## ğŸ­ Playwright E2E Test Results
          
          ### ${statusIcon} Test Status: ${(testJobResult === 'failure' || testFailed === 'true') ? 'FAILED' : 'PASSED'}
          
          ${testStatus}${statusDetails}
          
          **Test Coverage:**
          - âœ… Authentication flows (signup, signin, logout, remember user)
          - âœ… Transaction management (create, view, filter, comment, like)
          - âœ… Bank account operations (add, edit, delete, validation)
          - âœ… Notifications handling (view, mark read, dismiss, filter)
          - âœ… User settings management (profile, password, privacy)
          - âœ… End-to-end user journeys (complete workflows)
          
          **Browsers Tested:**
          - ğŸŒ Chromium (Desktop)
          
          **Reports:** Check the workflow artifacts for detailed HTML reports and screenshots.
          ${(testJobResult === 'failure' || testFailed === 'true') ? '\n\n**ğŸ” Debug Artifacts Available:**\n- DOM snapshots from failed tests\n- Screenshots of failure states\n- Video recordings of test execution\n- Playwright traces for detailed debugging\n- Error context files with page state\n\nDownload the \`dom-snapshots-and-debug-artifacts\` artifact to investigate failures.' : ''}
          
          ${(testJobResult === 'failure' || testFailed === 'true') ? 'âš ï¸ **Action Required:** Please fix the failing tests before merging.' : 'ğŸ‰ **Ready to merge!** All tests are passing.'}
          `;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });